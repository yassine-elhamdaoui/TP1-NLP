{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6be567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cab36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Téléchargement des ressources NLTK nécessaires\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba230056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données depuis le fichier sample.csv\n",
    "df = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c0c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant nettoyage :\n",
      "0     @AppleSupport causing the reply to be disregar...\n",
      "1     @105835 Your business means a lot to us. Pleas...\n",
      "2     @76328 I really hope you all change but I'm su...\n",
      "3     @105836 LiveChat is online at the moment - htt...\n",
      "4     @VirginTrains see attached error message. I've...\n",
      "                            ...                        \n",
      "88    @105860 I wish Amazon had an option of where I...\n",
      "89    They reschedule my shit for tomorrow https://t...\n",
      "90    @105861 Hey Sara, sorry to hear of the issues ...\n",
      "91    @Tesco bit of both - finding the layout cumber...\n",
      "92    @105861 If that doesn't help please DM your fu...\n",
      "Name: text, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Affichage de la colonne text_cleaned avant nettoyage\n",
    "print(\"Avant nettoyage :\")\n",
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0c558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après mise en minuscules :\n",
      "0     @applesupport causing the reply to be disregar...\n",
      "1     @105835 your business means a lot to us. pleas...\n",
      "2     @76328 i really hope you all change but i'm su...\n",
      "3     @105836 livechat is online at the moment - htt...\n",
      "4     @virgintrains see attached error message. i've...\n",
      "                            ...                        \n",
      "88    @105860 i wish amazon had an option of where i...\n",
      "89    they reschedule my shit for tomorrow https://t...\n",
      "90    @105861 hey sara, sorry to hear of the issues ...\n",
      "91    @tesco bit of both - finding the layout cumber...\n",
      "92    @105861 if that doesn't help please dm your fu...\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Mise en minuscules\n",
    "df['text_cleaned'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "# Affichage de la colonne text_cleaned après mise en minuscules\n",
    "print(\"\\nAprès mise en minuscules :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d025750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après suppression des ponctuations :\n",
      "0     applesupport causing the reply to be disregard...\n",
      "1     105835 your business means a lot to us please ...\n",
      "2     76328 i really hope you all change but im sure...\n",
      "3     105836 livechat is online at the moment  https...\n",
      "4     virgintrains see attached error message ive tr...\n",
      "                            ...                        \n",
      "88    105860 i wish amazon had an option of where i ...\n",
      "89    they reschedule my shit for tomorrow httpstcor...\n",
      "90    105861 hey sara sorry to hear of the issues yo...\n",
      "91    tesco bit of both  finding the layout cumberso...\n",
      "92    105861 if that doesnt help please dm your full...\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Suppression des ponctuations\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# Affichage de la colonne text_cleaned après suppression des ponctuations\n",
    "print(\"\\nAprès suppression des ponctuations :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c86627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après suppression des mots vides :\n",
      "0     applesupport causing reply disregarded tapped ...\n",
      "1     105835 business means lot us please dm name zi...\n",
      "2            76328 really hope change im sure wont dont\n",
      "3     105836 livechat online moment httpstcosy94vtu8...\n",
      "4     virgintrains see attached error message ive tr...\n",
      "                            ...                        \n",
      "88    105860 wish amazon option get shipped ups stor...\n",
      "89          reschedule shit tomorrow httpstcorsvzct982t\n",
      "90    105861 hey sara sorry hear issues ask lay spee...\n",
      "91    tesco bit finding layout cumbersome removing i...\n",
      "92    105861 doesnt help please dm full name address...\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Suppression des mots vides (stopwords)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "# Affichage de la colonne text_cleaned après suppression des mots vides\n",
    "print(\"\\nAprès suppression des mots vides :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be7fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après suppression des émojis, émoticônes, URL, balises HTML :\n",
      "0     applesupport causing reply disregarded tapped ...\n",
      "1     105835 business means lot us please dm name zi...\n",
      "2            76328 really hope change im sure wont dont\n",
      "3     105836 livechat online moment  contact 03331 0...\n",
      "4     virgintrains see attached error message ive tr...\n",
      "                            ...                        \n",
      "88    105860 wish amazon option get shipped ups stor...\n",
      "89                            reschedule shit tomorrow \n",
      "90    105861 hey sara sorry hear issues ask lay spee...\n",
      "91    tesco bit finding layout cumbersome removing i...\n",
      "92    105861 doesnt help please dm full name address...\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Suppression des émojis, émoticônes, URL, balises HTML (utilisation d'expressions régulières)\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'http\\S+|www\\S+|<[^>]+>', '', x))\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "\n",
    "# Affichage de la colonne text_cleaned après suppression des émojis, émoticônes, URL, balises HTML\n",
    "print(\"\\nAprès suppression des émojis, émoticônes, URL, balises HTML :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b8e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après suppression des mots extrêmement fréquents :\n",
      "0     applesupport causing reply disregarded tapped ...\n",
      "1     105835 business means lot us please dm name zi...\n",
      "2            76328 really hope change im sure wont dont\n",
      "3     105836 livechat online moment contact 03331 03...\n",
      "4     virgintrains see attached error message ive tr...\n",
      "                            ...                        \n",
      "88    105860 wish amazon option get shipped ups stor...\n",
      "89                             reschedule shit tomorrow\n",
      "90    105861 hey sara sorry hear issues ask lay spee...\n",
      "91    tesco bit finding layout cumbersome removing i...\n",
      "92    105861 doesnt help please dm full name address...\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Suppression des mots extrêmement fréquents\n",
    "# Compter la fréquence de chaque mot dans le corpus\n",
    "word_freq = Counter()\n",
    "df['text_cleaned'].str.split().apply(word_freq.update)\n",
    "\n",
    "# Déterminer les mots extrêmement fréquents (par exemple, les mots qui apparaissent dans plus de 90% des documents)\n",
    "total_docs = len(df)\n",
    "common_words = [word for word, freq in word_freq.items() if freq > total_docs * 0.9]\n",
    "\n",
    "# Supprimer les mots extrêmement fréquents\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join(word for word in x.split() if word not in common_words))\n",
    "\n",
    "# Affichage de la colonne text_cleaned après suppression des mots extrêmement fréquents\n",
    "print(\"\\nAprès suppression des mots extrêmement fréquents :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "222937e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après suppression des mots rares :\n",
      "0                          applesupport\n",
      "1                     us please dm name\n",
      "2                                      \n",
      "3                                  back\n",
      "4                             ive tried\n",
      "                    ...                \n",
      "88                                  get\n",
      "89                                     \n",
      "90                                sorry\n",
      "91                                tesco\n",
      "92    help please dm name device thanks\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Suppression des mots rares\n",
    "# Déterminer les mots rares (par exemple, les mots qui apparaissent dans moins de 5 documents)\n",
    "rare_words = [word for word, freq in word_freq.items() if freq < 5]\n",
    "\n",
    "# Supprimer les mots rares\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join(word for word in x.split() if word not in rare_words))\n",
    "\n",
    "# Affichage de la colonne text_cleaned après suppression des mots rares\n",
    "print(\"\\nAprès suppression des mots rares :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426e4340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après stemming :\n",
      "0                       applesupport\n",
      "1                   us pleas dm name\n",
      "2                                   \n",
      "3                               back\n",
      "4                            ive tri\n",
      "                   ...              \n",
      "88                               get\n",
      "89                                  \n",
      "90                             sorri\n",
      "91                             tesco\n",
      "92    help pleas dm name devic thank\n",
      "Name: text_cleaned, Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join(stemmer.stem(word) for word in x.split()))\n",
    "\n",
    "# Affichage de la colonne text_cleaned après stemming\n",
    "print(\"\\nAprès stemming :\")\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b3e0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tweet_id                                               text  \\\n",
      "0          1  @AppleSupport causing the reply to be disregar...   \n",
      "1          2  @105835 Your business means a lot to us. Pleas...   \n",
      "2          3  @76328 I really hope you all change but I'm su...   \n",
      "3          4  @105836 LiveChat is online at the moment - htt...   \n",
      "4          5  @VirginTrains see attached error message. I've...   \n",
      "..       ...                                                ...   \n",
      "88        89  @105860 I wish Amazon had an option of where I...   \n",
      "89        90  They reschedule my shit for tomorrow https://t...   \n",
      "90        91  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91        92  @Tesco bit of both - finding the layout cumber...   \n",
      "92        93  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                      text_cleaned  \n",
      "0                     applesupport  \n",
      "1                 us pleas dm name  \n",
      "2                                   \n",
      "3                             back  \n",
      "4                          ive tri  \n",
      "..                             ...  \n",
      "88                             get  \n",
      "89                                  \n",
      "90                           sorri  \n",
      "91                           tesco  \n",
      "92  help pleas dm name devic thank  \n",
      "\n",
      "[93 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ajout de la colonne 'tweet_id' avec des valeurs par défaut pour l'exemple\n",
    "df['tweet_id'] = range(1, len(df) + 1)\n",
    "\n",
    "# Réorganiser les colonnes dans l'ordre requis\n",
    "df = df[['tweet_id', 'text', 'text_cleaned']]\n",
    "\n",
    "# Affichage du dataframe final\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f276d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
